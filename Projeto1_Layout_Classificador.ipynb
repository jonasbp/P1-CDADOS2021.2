{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Guilermo Kuznietz\n",
    "\n",
    "Nome: Jonas Bonfá Pelegrina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "/Users/jonas/OneDrive - Insper - Institudo de Ensino e Pesquisa/2021.2/Ciência dos Dados/P1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'alexa_b.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>la música da vida</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>alexa play me odio by matias candia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>cemre:vocês queriam tanto que eu aparecesse qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>@karnecita alexa: https://t.co/tc5hbjcuuy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>alexa, da mis clases híbridas.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Classificacao\n",
       "295                                  la música da vida              0\n",
       "296                alexa play me odio by matias candia              0\n",
       "297  cemre:vocês queriam tanto que eu aparecesse qu...              0\n",
       "298          @karnecita alexa: https://t.co/tc5hbjcuuy              0\n",
       "299                     alexa, da mis clases híbridas.              0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eu odeio quando eu peço pra alexa tocar a musi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alexa play digital dash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muito bom conversar com a alexa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perguntei pra alexa se podia chamar ela de jar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e a alexa que tá fazendo elogios antes de dar ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classificacao\n",
       "0  eu odeio quando eu peço pra alexa tocar a musi...              1\n",
       "1                            alexa play digital dash              1\n",
       "2                    muito bom conversar com a alexa              1\n",
       "3  perguntei pra alexa se podia chamar ela de jar...              1\n",
       "4  e a alexa que tá fazendo elogios antes de dar ...              1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/alexa_logo.png\" alt=\"Alexa logo\" width=\"500\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso projeto busca entender o uso da Alexa no mercado brasileiro como os usuário interagem com ela e quais são as principais reações sobre o produto.\n",
    "\n",
    "Exemplos de casos relevantes:\n",
    "- Alexa,como está o dia hoje?\n",
    "- Eu e minha família adoramos a Alexa\n",
    "- A Alexa me entende como vivia antes sem ela?\n",
    "\n",
    "Exemplos de casos irrelevante:\n",
    "- Queria comprar uma Alexa\n",
    "- Eu amo minha amiga que chama Alexa\n",
    "- Tenho quatro filhas: Beatriz,Maria e Alexa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpeza de mensagens removendo os caracteres especiais\n",
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;@]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'duda_barroso1 alexa o que tenho pra hj'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup('@duda_barroso1 alexa, o que tenho pra hj?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#RELEVANTE\n",
    "train_relevante = train.loc[train['Classificacao'] == 1,'Treinamento']\n",
    "lista = []\n",
    "lista_relevante = []\n",
    "\n",
    "for i in range(0,len(train_relevante)):\n",
    "    lista.append(cleanup(train_relevante[i]).split())\n",
    "\n",
    "for lista1 in lista:\n",
    "    for palavra in lista1:\n",
    "        if \"https\" not in palavra:\n",
    "            lista_relevante.append(palavra)\n",
    "\n",
    "#RELEVANTE\n",
    "train_irrelevante = train.loc[train['Classificacao'] == 0,'Treinamento']\n",
    "lista = []\n",
    "lista_irrelevante = []\n",
    "\n",
    "for frase in train_irrelevante:\n",
    "    lista.append(cleanup(frase).split())\n",
    "\n",
    "for lista1 in lista:\n",
    "    for palavra in lista1:\n",
    "        if \"https\" not in palavra:\n",
    "            lista_irrelevante.append(palavra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificando as frequências**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alexa           156\n",
       "a                89\n",
       "eu               59\n",
       "e                46\n",
       "pra              45\n",
       "               ... \n",
       "alineygarcia      1\n",
       "peguei            1\n",
       "ligado            1\n",
       "posso             1\n",
       "pariu             1\n",
       "Length: 796, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RELEVANTE - FREQUENCIA ABSOLUTA\n",
    "serie_relevante = pd.Series(lista_relevante)\n",
    "serie_relevante.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RELEVANTE - FREQUENCIA RELATIVA\n",
    "serie_relevante = pd.Series(lista_relevante)\n",
    "serie_relevante_relativa = serie_relevante.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alexa         86\n",
       "de            47\n",
       "a             41\n",
       "e             36\n",
       "que           30\n",
       "              ..\n",
       "sala           1\n",
       "tik            1\n",
       "aceita         1\n",
       "mykaaa         1\n",
       "aparecesse     1\n",
       "Length: 951, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IRRELEVANTE - FREQUENCIA ABSOLUTA\n",
    "serie_irrelevante = pd.Series(lista_irrelevante)\n",
    "serie_irrelevante.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRRELEVANTE - FREQUENCIA RELATIVA\n",
    "serie_irrelevante = pd.Series(lista_irrelevante)\n",
    "serie_irrelevante_relativa = serie_irrelevante.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMANDO EM UM GRANDE TEXTO\n",
    "\n",
    "livro_relevante = \" \".join(lista_relevante)\n",
    "\n",
    "livro_irrelevante = \" \".join(lista_irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexa         0.060553\n",
      "a             0.032663\n",
      "de            0.022613\n",
      "e             0.020603\n",
      "eu            0.019849\n",
      "                ...   \n",
      "ceu           0.000251\n",
      "posso         0.000251\n",
      "passou        0.000251\n",
      "alexa_cc07    0.000251\n",
      "aparecesse    0.000251\n",
      "Length: 1535, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# JUNTANDO TODAS AS PALAVRAS\n",
    "todas_palavras = livro_relevante + livro_irrelevante\n",
    "todas_palavras = todas_palavras.split()\n",
    "series_todas_palavras = pd.Series(todas_palavras)\n",
    "series_todas_palavras_relativas = series_todas_palavras.value_counts(True)\n",
    "print(series_todas_palavras_relativas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBABILIDADES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07482014388489208"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_relevante_relativa['alexa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04535864978902954"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_irrelevante_relativa['alexa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P(R) E P(I)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de ser relevante é 0.5238693467336684\n"
     ]
    }
   ],
   "source": [
    "probR = len(serie_relevante) / len(series_todas_palavras)\n",
    "print(f\"A probabilidade de ser relevante é {probR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de ser irrelevante é 0.4763819095477387\n"
     ]
    }
   ],
   "source": [
    "probI = len(serie_irrelevante) / len(series_todas_palavras)\n",
    "print(f\"A probabilidade de ser irrelevante é {probI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frequência Absoluta das palavras nos Tweets relevantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras Relevantes,totais: 2085\n",
      "Palavras Relevantes,não repetidas:  796\n"
     ]
    }
   ],
   "source": [
    "livro_relevante_series = pd.Series(livro_relevante.split())\n",
    "livro_relevante_series = livro_relevante_series.value_counts()\n",
    "soma_relevantes = livro_relevante_series.sum()\n",
    "print('Palavras Relevantes,totais:',soma_relevantes)\n",
    "print('Palavras Relevantes,não repetidas: ',len(livro_relevante_series))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frequência Absoluta das palavras nos Tweets irrelevantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras Relevantes,totais: 1896\n",
      "Palavras Relevantes,não repetidas:  951\n"
     ]
    }
   ],
   "source": [
    "livro_irrelevante_series = pd.Series(livro_irrelevante.split())\n",
    "livro_irrelevante_series = livro_irrelevante_series.value_counts()\n",
    "soma_irrelevantes = livro_irrelevante_series.sum()\n",
    "print('Palavras Relevantes,totais:',soma_irrelevantes)\n",
    "print('Palavras Relevantes,não repetidas: ',len(livro_irrelevante_series))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FREQUÊNCIA ABSOLUTA TOTAL** <br>\n",
    "Frequencia Absoluta com relevantes e irrelevantes juntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O total de palavras na base é de: 3980\n"
     ]
    }
   ],
   "source": [
    "print(\"O total de palavras na base é de:\",len(series_todas_palavras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Começando a calcular**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eu odeio quando eu peço pra alexa tocar a musi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alexa play digital dash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muito bom conversar com a alexa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perguntei pra alexa se podia chamar ela de jar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e a alexa que tá fazendo elogios antes de dar ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classificacao\n",
       "0  eu odeio quando eu peço pra alexa tocar a musi...              1\n",
       "1                            alexa play digital dash              1\n",
       "2                    muito bom conversar com a alexa              1\n",
       "3  perguntei pra alexa se podia chamar ela de jar...              1\n",
       "4  e a alexa que tá fazendo elogios antes de dar ...              1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Limpeza\n",
    "#Suavização\n",
    "frase = cleanup(test.iloc[2,0])\n",
    "frase_quebrada = frase.split()\n",
    "palavras_frase = pd.Series(frase_quebrada)\n",
    "contador_palavras = len(palavras_frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase_d_relevante = 1\n",
    "for palavra in palavras_frase:\n",
    "    if palavra in livro_relevante_series:\n",
    "        frase_d_relevante = frase_d_relevante * (livro_relevante_series[palavra] + 1) / (soma_relevantes + len(todas_palavras))\n",
    "    else:\n",
    "        frase_d_relevante = frase_d_relevante * 1 / (soma_relevantes + len(todas_palavras))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "muito        0.000959\n",
       "bom          0.002398\n",
       "conversar    0.001918\n",
       "com          0.014868\n",
       "a            0.042686\n",
       "alexa        0.074820\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probFraseDadoR = serie_relevante_relativa[palavras_frase]\n",
    "# probFraseDadoR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
